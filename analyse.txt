Quelques éléments de réfléxion et d'analyse

1)2) Effet du ratio taille fichier/taille cache pour les différents tests

Test 1 : boucle de lecture séquentielle
On voit que ce test donne de bons résultats pour toutes les stratégies (à peu près 95% de hit rate) sauf la stratégie aléatoire qui est moins performante.

Test 2 : boucle d'écriture aléatoire
Ce test ne donne pas de bons résultats et cela pour n'importe quelle stratégie. Lorsque la taille du fichier augmente, la performance des stratégies s'effondre. Cela est dû au fait que l'enregistrement est choisi aléatoirement (probabilité qu'un enregistrement soit dans le cache : taille du cache/taille du fichier).

Test 3 : boucle de lecture/écriture aléatoire
Il donne des résultats variés. On voit que le hit rate augmente très rapidement et au delà de 100 blocs locaux, il devient négligeable.

Tests 4 et 5 : boucle de lecture/écriture aléatoire avec localité améliorée

C'est avec ces 2 tests qu'on peut vraiment comparer toutes les stratégies, elles apparaissent toutes sur le graphe.
Le test 5 est quand même meilleur car par rapport au test 4 il parcourt le fichier séquentiellement.

La stratégie RAND est toujours la plus mauvaise de par son caractère aléatoire et LRU est la meilleure stratégie puisqu'on ne remplace jamais un bloc que l'on vient d'utiliser.
Pour les tests 4 et 5, on a de bons hit rates même pour des toutes petites tailles de cache. Donc ili n'est pas nécessaire d'augmenter la taille du cache au delà de 15% environ du fichier (voir la courbe inversée avec en abscisse taille cache/taille fichier).

3) D'après les courbes des tests 3 à 5, le ratio nb de lectures/nb d'écritures n'a pas d'influence (on obtient des droites constantes). 
NUR est l'unique stratégie tenant compte des lectures/écritures (avec le bit M).

4) Les résultats du test 3 dépendent du nombre d'enregistrements qui sont accédés localement autour de l'enregistrement courant. Le hit rate augmente très rapidement et au délà de 100 blocs locaux il devient négligeable (plafond à 90%)

5) Working sets : ce nombre représente le nombre de places dans lesquelles le programme a un comportement local (c'est-à-dire que le programme n'accède qu'à des enregistrement de la même zone). On remarque que plus le nombre de phases est grand et plus le programme change de zone. Au début le hit rate est très élevé et puis à partir d'un certain nombre de working sets le hit rate diminue fortement.

6) La largeur de fenêtre de localité mesure la taille du Working Set. Dans t4/t5-locality, on voit que le hit rate s'affondre à partir d'une fenêtre de 300 enregistrements (logique car par défaut il y a 300 enregistrements dans le cache : 30 blocs avec 10 enregistrements par bloc).
Dès que la fenêtre de localité ne tient plus entièrement dans le cache, le hit rate devient mauvais.

7) Pour les petites valeurs de NDEREF (t5-nderef) le hit rate est mauvais car on remet R à 0 beaucoup de fois. C'est pourtant nécessaire car sinon les blocs inutilisés vont rester dans le cache et on aura du mal à choisir le bloc à remplacer. Ce cas de figure se réalise pour de grandes valeurs de déréférençages.
De plus on peut constater que pour la taille de cache par défaut (360000/3600 = 100 = valeur de déréférençage = r et taille cache/taille fichier = 1%) ou pour des tailles de caches plus grande, la valeur r semble judicieuse car le hit rate est à plus de 80%!

